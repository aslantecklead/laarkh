import time
from pathlib import Path
from typing import Dict, Any, Union, Optional, List
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
import numpy as np
import os
import subprocess
import tempfile
import logging

from faster_whisper import WhisperModel

logger = logging.getLogger(__name__)

# ---------------------------
# Model cache with persistent storage
# ---------------------------
_MODEL_CACHE: Dict[tuple, WhisperModel] = {}
_MODEL_LOCK = threading.Lock()

# –°–æ–∑–¥–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –∫—ç—à–∞ –º–æ–¥–µ–ª–µ–π Linguada
LINGUADA_CACHE_DIR = Path.home() / ".cache" / "linguada" / "models"
LINGUADA_CACHE_DIR.mkdir(parents=True, exist_ok=True)

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
os.environ["HF_HOME"] = str(LINGUADA_CACHE_DIR)
os.environ["TRANSFORMERS_CACHE"] = str(LINGUADA_CACHE_DIR)
os.environ["HF_DATASETS_CACHE"] = str(LINGUADA_CACHE_DIR)


# –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ –∫—ç—à–µ
def _is_model_cached(model_size: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –µ—Å—Ç—å –ª–∏ –º–æ–¥–µ–ª—å –≤ –∫—ç—à–µ"""
    model_dir = LINGUADA_CACHE_DIR / f"models--Systran--faster-whisper-{model_size}"
    return model_dir.exists() and any(model_dir.glob("**/*.bin"))


def _get_model(model_size: str, compute_type: str, num_workers: int = 4) -> WhisperModel:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–æ–π –≤–æ—Ä–∫–µ—Ä–æ–≤"""
    key = (model_size, compute_type, num_workers)

    with _MODEL_LOCK:
        model = _MODEL_CACHE.get(key)
        if model is None:
            # CPU-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
            cpu_count = os.cpu_count() or 4
            threads = min(num_workers, cpu_count)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
            if not _is_model_cached(model_size):
                logger.info(f"Model {model_size} not found in cache, downloading...")
            else:
                logger.info(f"Loading model {model_size} from cache...")

            # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –∫—ç—à–∞
            model = WhisperModel(
                model_size,
                device="cpu",
                compute_type=compute_type,
                cpu_threads=threads,  # –í–∞–∂–Ω–æ –¥–ª—è CPU!
                num_workers=threads,  # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
                download_root=str(LINGUADA_CACHE_DIR),  # –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
            )
            _MODEL_CACHE[key] = model
            logger.info(
                f"‚úÖ Loaded model {model_size} with {threads} CPU threads (cached: {_is_model_cached(model_size)})")
        return model


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π
def preload_models():
    """–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    logger.info("Starting model preloading...")

    # –ú–æ–¥–µ–ª–∏ –¥–ª—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
    models_to_preload = [
        ("tiny", "int8", 2),
        ("base", "int8", 2),
    ]

    for model_size, compute_type, workers in models_to_preload:
        try:
            _get_model(model_size, compute_type, workers)
            logger.info(f"‚úì Preloaded model: {model_size}")
        except Exception as e:
            logger.warning(f"Failed to preload {model_size}: {e}")


# ---------------------------
# Ultra Fast Whisper ASR
# ---------------------------
class WhisperASR:
    """
    –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û –ë–´–°–¢–†–´–ô Whisper –Ω–∞ CPU
    –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è –º–∞—Å—Å–æ–≤–æ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
    """

    def __init__(
            self,
            *,
            model_size: str = "tiny",  # üöÄ –°–∞–º—ã–π –±—ã—Å—Ç—Ä—ã–π
            compute_type: str = "int8",  # üöÄ –õ—É—á—à–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –Ω–∞ CPU
            language: Optional[str] = "en",  # üöÄ –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —è–∑—ã–∫ = +30% —Å–∫–æ—Ä–æ—Å—Ç–∏
            vad_filter: bool = True,  # üöÄ –£–±–∏—Ä–∞–µ—Ç —Ç–∏—à–∏–Ω—É
            num_workers: int = 4,  # üöÄ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ (–æ–±–Ω–æ–≤–ª–µ–Ω–æ –¥–æ 4)
            beam_size: int = 1,  # üöÄ Greedy –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ
    ):
        self.model_size = model_size
        self.compute_type = compute_type
        self.language = language
        self.vad_filter = vad_filter
        self.num_workers = max(1, num_workers)
        self.beam_size = beam_size

        # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
        self.transcribe_kwargs = {
            "language": self.language,
            "beam_size": self.beam_size,
            "best_of": 1,  # üöÄ –ú–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞
            "temperature": 0.0,  # üöÄ –î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–≤–æ–¥
            "compression_ratio_threshold": 1.8,  # üöÄ –ú–µ–Ω—å—à–µ –ø—Ä–æ–≤–µ—Ä–æ–∫
            "log_prob_threshold": -0.5,  # üöÄ –ú–µ–Ω—å—à–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
            "no_speech_threshold": 0.4,  # üöÄ –ú–µ–Ω—å—à–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤ —Ç–∏—à–∏–Ω—ã
            "condition_on_previous_text": False,  # üöÄ –ù–µ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            "initial_prompt": None,  # üöÄ –ë–µ–∑ –ø—Ä–æ–º–ø—Ç–∞
            "word_timestamps": True,  # ‚úÖ –¢—Ä–µ–±—É–µ—Ç—Å—è –ø–æ –∑–∞–¥–∞–Ω–∏—é
            "prepend_punctuations": "\"'‚Äú¬ø([{-",  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            "append_punctuations": "\"'.„ÄÇ,Ôºå!ÔºÅ?Ôºü:Ôºö‚Äù)]}„ÄÅ",  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            "vad_filter": self.vad_filter,
            "vad_parameters": {
                "threshold": 0.3,  # üöÄ –ë–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π VAD
                "min_speech_duration_ms": 250,
                "max_speech_duration_s": float('inf'),
                "min_silence_duration_ms": 200,
            }
        }

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ –Ω–∞—à –∫—ç—à
        self.model = _get_model(model_size, compute_type, self.num_workers)

    def transcribe(self, audio_path: Union[str, Path]) -> Dict[str, Any]:
        audio_path = Path(audio_path)
        if not audio_path.exists():
            raise FileNotFoundError(audio_path)

        t0 = time.perf_counter()

        # üöÄ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª–∏–Ω–Ω—ã—Ö –∞—É–¥–∏–æ
        if self._should_split_audio(audio_path):
            return self._transcribe_parallel(audio_path)

        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ñ–∞–π–ª–æ–≤
        segments_iter, info = self.model.transcribe(
            str(audio_path),
            **self.transcribe_kwargs
        )

        # üöÄ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
        segments_out = self._process_segments_parallel(segments_iter)

        asr_time = time.perf_counter() - t0
        result = self._build_result(segments_out, info, asr_time, audio_path)

        return result

    def _should_split_audio(self, audio_path: Path, threshold_sec: int = 300) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ —Ä–∞–∑–±–∏–≤–∞—Ç—å –∞—É–¥–∏–æ –Ω–∞ —á–∞—Å—Ç–∏ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        try:
            cmd = [
                "ffprobe", "-v", "error",
                "-show_entries", "format=duration",
                "-of", "default=noprint_wrappers=1:nokey=1",
                str(audio_path)
            ]
            result = subprocess.run(cmd, capture_output=True, text=True)
            duration = float(result.stdout.strip())
            return duration > threshold_sec and self.num_workers > 1
        except:
            return False

    def _transcribe_parallel(self, audio_path: Path) -> Dict[str, Any]:
        """–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –¥–ª–∏–Ω–Ω—ã—Ö –∞—É–¥–∏–æ"""
        t0 = time.perf_counter()

        # –†–∞–∑–±–∏–≤–∞–µ–º –∞—É–¥–∏–æ –Ω–∞ —á–∞—Å—Ç–∏
        audio_chunks = self._split_audio_into_chunks(audio_path)

        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞–Ω–∫–æ–≤
        all_segments = []
        with ThreadPoolExecutor(max_workers=self.num_workers) as executor:
            futures = []
            for chunk_path in audio_chunks:
                future = executor.submit(self._transcribe_chunk, chunk_path)
                futures.append(future)

            for future in as_completed(futures):
                segments, chunk_start = future.result()
                # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º —Ç–∞–π–º–∫–æ–¥—ã
                for seg in segments:
                    seg["start"] += chunk_start
                    seg["end"] += chunk_start
                    if "words" in seg:
                        for word in seg["words"]:
                            word["start"] += chunk_start
                            word["end"] += chunk_start
                all_segments.extend(segments)

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        all_segments.sort(key=lambda x: x["start"])

        # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        for chunk in audio_chunks:
            chunk.unlink(missing_ok=True)

        asr_time = time.perf_counter() - t0
        result = self._build_result(all_segments, None, asr_time, audio_path)

        return result

    def _split_audio_into_chunks(self, audio_path: Path, chunk_duration: int = 180) -> List[Path]:
        """–†–∞–∑–±–∏–≤–∞–µ–º –∞—É–¥–∏–æ –Ω–∞ —á–∞–Ω–∫–∏ –ø–æ N —Å–µ–∫—É–Ω–¥"""
        chunks = []
        temp_dir = tempfile.mkdtemp(prefix="whisper_chunks_")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–ª–∏–Ω—É –∞—É–¥–∏–æ
        cmd = [
            "ffprobe", "-v", "error",
            "-show_entries", "format=duration",
            "-of", "default=noprint_wrappers=1:nokey=1",
            str(audio_path)
        ]
        result = subprocess.run(cmd, capture_output=True, text=True)
        total_duration = float(result.stdout.strip())

        # –°–æ–∑–¥–∞–µ–º —á–∞–Ω–∫–∏
        for i, start in enumerate(np.arange(0, total_duration, chunk_duration)):
            chunk_path = Path(temp_dir) / f"chunk_{i:03d}.wav"

            cmd = [
                "ffmpeg", "-i", str(audio_path),
                "-ss", str(start),
                "-t", str(chunk_duration),
                "-ar", "16000",
                "-ac", "1",
                "-acodec", "pcm_s16le",
                "-y", str(chunk_path)
            ]

            subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=False)

            if chunk_path.exists() and chunk_path.stat().st_size > 0:
                chunks.append(chunk_path)

        # –ï—Å–ª–∏ —á–∞–Ω–∫–∏ –Ω–µ —Å–æ–∑–¥–∞–ª–∏—Å—å, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª –∫–∞–∫ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π —á–∞–Ω–∫
        if not chunks:
            return [audio_path]

        return chunks

    def _transcribe_chunk(self, chunk_path: Path):
        """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –æ–¥–Ω–æ–≥–æ —á–∞–Ω–∫–∞"""
        # –ü–æ–ª—É—á–∞–µ–º –≤—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ —á–∞–Ω–∫–∞ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        chunk_start = 0
        if "_" in chunk_path.stem:
            try:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–º–µ—Ä –∏–∑ –∏–º–µ–Ω–∏ —Ç–∏–ø–∞ "chunk_000"
                parts = chunk_path.stem.split("_")
                if len(parts) > 1 and parts[-1].isdigit():
                    chunk_num = int(parts[-1])
                    chunk_start = chunk_num * 180  # 3 –º–∏–Ω—É—Ç—ã –Ω–∞ —á–∞–Ω–∫
            except:
                pass

        segments_iter, _ = self.model.transcribe(
            str(chunk_path),
            **self.transcribe_kwargs
        )

        segments = []
        for i, seg in enumerate(segments_iter):
            segment_data = self._process_segment(i, seg)
            segments.append(segment_data)

        return segments, chunk_start

    def _process_segments_parallel(self, segments_iter):
        """–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–µ–≥–º–µ–Ω—Ç–æ–≤"""
        segments = []

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Å–µ–≥–º–µ–Ω—Ç—ã —Å–Ω–∞—á–∞–ª–∞
        segment_list = list(enumerate(segments_iter))

        if not segment_list:
            return segments

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤ –ø—É–ª–µ –ø–æ—Ç–æ–∫–æ–≤
        with ThreadPoolExecutor(max_workers=min(4, self.num_workers)) as executor:
            futures = [executor.submit(self._process_segment, i, seg)
                       for i, seg in segment_list]

            for future in as_completed(futures):
                segments.append(future.result())

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ ID
        segments.sort(key=lambda x: x["id"])
        return segments

    def _process_segment(self, idx: int, seg) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞"""
        text = (seg.text or "").strip()

        segment_data = {
            "id": idx,
            "start": float(seg.start),
            "end": float(seg.end),
            "text": text,
            "words": [],
        }

        if hasattr(seg, 'words') and seg.words:
            segment_data["words"] = [
                {
                    "word": (w.word or "").strip(),
                    "start": float(w.start),
                    "end": float(w.end),
                    "confidence": float(w.probability) if w.probability is not None else 0.9,
                }
                for w in seg.words
            ]

        return segment_data

    def _build_result(self, segments_out, info, asr_time: float, audio_path: Path) -> Dict[str, Any]:
        """–°–±–æ—Ä–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"""
        # –ü–æ–ª—É—á–∞–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞—É–¥–∏–æ
        duration = None
        if segments_out:
            duration = segments_out[-1]["end"]
        else:
            try:
                cmd = [
                    "ffprobe", "-v", "error",
                    "-show_entries", "format=duration",
                    "-of", "default=noprint_wrappers=1:nokey=1",
                    str(audio_path)
                ]
                result = subprocess.run(cmd, capture_output=True, text=True)
                duration = float(result.stdout.strip())
            except:
                duration = None

        # –°–æ–±–∏—Ä–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç
        full_text = " ".join([seg["text"] for seg in segments_out if seg["text"].strip()])

        rtf = asr_time / duration if duration and duration > 0 else None

        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫—ç—à–µ
        cache_info = {
            "cached": _is_model_cached(self.model_size),
            "cache_dir": str(LINGUADA_CACHE_DIR),
            "cache_size_mb": self._get_cache_size_mb(),
        }

        return {
            "text": full_text,
            "language": getattr(info, "language", self.language) if info else self.language,
            "segments": segments_out,
            "meta": {
                "engine": "ultra-fast-whisper",
                "model": self.model_size,
                "compute_type": self.compute_type,
                "device": "cpu",
                "num_workers": self.num_workers,
                "beam_size": self.beam_size,
                "language_hint": self.language,
                "vad_filter": self.vad_filter,
                "duration_audio_sec": duration,
                "asr_time_sec": round(asr_time, 2),
                "rtf": round(rtf, 3) if rtf else None,
                "speedup_factor": round((duration or 0) / asr_time, 1) if asr_time > 0 else None,
                "cache": cache_info,
            },
        }

    def _get_cache_size_mb(self) -> float:
        """–ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä –∫—ç—à–∞ –≤ MB"""
        try:
            total_size = 0
            for path in LINGUADA_CACHE_DIR.rglob("*"):
                if path.is_file():
                    total_size += path.stat().st_size
            return round(total_size / (1024 * 1024), 2)
        except:
            return 0.0


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –∫—ç—à–∞
def clear_model_cache():
    """–û—á–∏—â–∞–µ—Ç –∫—ç—à –º–æ–¥–µ–ª–µ–π"""
    try:
        import shutil
        if LINGUADA_CACHE_DIR.exists():
            shutil.rmtree(LINGUADA_CACHE_DIR)
            logger.info(f"Cache cleared: {LINGUADA_CACHE_DIR}")
        # –°–æ–∑–¥–∞–µ–º –∑–∞–Ω–æ–≤–æ –ø—É—Å—Ç—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
        LINGUADA_CACHE_DIR.mkdir(parents=True, exist_ok=True)
        return True
    except Exception as e:
        logger.error(f"Failed to clear cache: {e}")
        return False


# –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∏
__all__ = ['WhisperASR', 'preload_models', 'clear_model_cache']